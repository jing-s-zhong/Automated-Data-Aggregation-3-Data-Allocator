!set variable_substitution=true;
use database &{db_name};
use schema &{sc_name};
!set variable_substitution=false;
--
-------------------------------------------------------
-- Create task management tables
-------------------------------------------------------
--
-- CREATE TABLE DATA_ALLOCATION_BUCKETS;
-- CREATE TABLE DATA_ALLOCATION_TARGETS;
-- CREATE TABLE DATA_AGGREGATION_SOURCES;
-- CREATE FUNCTION DATA_PATTERN(ARRAY);
-- CREATE FUNCTION COLUMN_MAP(ARRAY);
-- CREATE FUNCTION REVENUE_SHARE(VARIANT, VARCHAR, FLOAT);
-- CREATE FUNCTION REVENUE_SHARE(VARIANT, VARCHAR);
-- CREATE PROCEDURE DATA_AGGREGATOR(VARCHAR, BOOLEAN, BOOLEAN, BOOLEAN, VARCHAR);
-- CREATE PROCEDURE DATA_AGGREGATOR(VARCHAR, BOOLEAN, BOOLEAN);
--
-------------------------------------------------------
-- Test 2 types of the DATA_PATTERN function calls, type 1 is used by setup automation
-------------------------------------------------------
-------------------------------------------------------
-- Create two dummy aggreagtion data targets
-------------------------------------------------------
--
-- Add ration columns on aggregation data target 1
--
CREATE OR REPLACE TRANSIENT TABLE _TEST_DATA_TARGET_1 
AS
SELECT DATA_PT
    ,DATA_DN
    ,DATA_DT
    ,DATA_HR
    ,DATA_TS
    ,DATA_I1
    ,DATA_I2
    ,DATA_I3
    ,DATA_A1
    ,DATA_A2
    ,DATA_A3
    ,VSUM_I1
    ,VCNT_I2
    ,VSUM_D1
    ,VAVG_D2
    ,NULL:FLOAT VSUM_I1_RATIO
	,NULL:FLOAT VCNT_I2_RATIO
	,NULL:FLOAT VSUM_D1_RATIO
	,NULL:FLOAT VAVG_D2_RATIO
FROM _TEST_DATA_TARGET_1
;
--
-- Register the tagegt table 1
--
-- DELETE FROM DATA_ALLOCATION_TARGETS WHERE TARGET_TABLE = '_TEST_DATA_TARGET_2';
-- Update or add the aggregation target
MERGE INTO DATA_ALLOCATION_TARGETS D
USING (
  SELECT 'Test: dummy allocation target 1' TARGET_LABEL
  	,$1 TARGET_TABLE
  	,$2 BATCH_CONTROL_COLUMN
  	,$3 BATCH_CONTROL_SIZE
  	,$4 BATCH_CONTROL_NEXT
  	,DATE_TRUNC('DAY', CURRENT_DATE ()-7) BATCH_PROCESSED
  	,NULL BATCH_PROCESSING
  	,NULL BATCH_MICROCHUNK_CURRENT
  	,$5 BATCH_SCHEDULE_TYPE
  	,NULL BATCH_SCHEDULE_LAST
  	,PARSE_JSON($6) PATTERN_COLUMNS
  	,PARSE_JSON($7) GROUPBY_COLUMNS
  	,DATA_PATTERN(PARSE_JSON($8)) GROUPBY_PATTERN
  	,true GROUPBY_FLEXIBLE
  	,PARSE_JSON($9) AGGREGATE_COLUMNS
  	,PARSE_JSON($10) AGGREGATE_FUNCTIONS
  	,NULL DEFAULT_PROCEDURE
  FROM VALUES (
  	'_TEST_DATA_TARGET_2'
  	,'DATA_TS'
  	, 1440
  	,'DATEADD(MINUTE, :2, :1)'
  	,'DAILY'
  	-- all group-by columns in source data
  	,'["DATA_PATTERN",
  		"DATA_NAME",
  		"DATA_DATE",
  		"DATA_HOUR",
  		"DATA_TIME",
  		"DATA_I1",
  		"DATA_I2",
  		"DATA_I3",
  		"DATA_A1",
  		"DATA_A2",
  		"DATA_A3"
        ]'
  	-- group-by columns of target data and which source column is the match
  	,'["DATA_DT:DATA_DATE",
  		"DATA_I1:DATA_I1",
  		"DATA_I2:DATA_I2",
  		"DATA_I3:DATA_I3",
  		"DATA_A1:DATA_A1",
  		"DATA_A2:DATA_A2",
  		"DATA_A3:DATA_A3"
         ]'
  	-- indicators of which group-by column are needed in target table
  	,'[0,0,1,0,0,1,1,1,1,1,1]'
  	-- aggregate columns of target data and which aggregating column is the match
  	,'["VSUM_I1:VALUE_I1","VCNT_I2:VALUE_I2","VSUM_D1:VALUE_D1","VAVG_D2:VALUE_D2"]'
  	-- what aggregation function will be used for every aggregation column
  	,'["SUM(?)","COUNT(DISTINCT ?)","SUM(?)","ROUND(AVG(?),2)"]'
  	)
  ) S
ON D.TARGET_TABLE = S.TARGET_TABLE
WHEN MATCHED THEN UPDATE SET
  TARGET_LABEL = S.TARGET_LABEL
  ,TARGET_TABLE = S.TARGET_TABLE
  ,BATCH_CONTROL_COLUMN = S.BATCH_CONTROL_COLUMN
  ,BATCH_CONTROL_SIZE = S.BATCH_CONTROL_SIZE
  ,BATCH_CONTROL_NEXT = S.BATCH_CONTROL_NEXT
  ,BATCH_PROCESSED = S.BATCH_PROCESSED
  ,BATCH_PROCESSING = S.BATCH_PROCESSING
  ,BATCH_MICROCHUNK_CURRENT = S.BATCH_MICROCHUNK_CURRENT
  ,BATCH_SCHEDULE_TYPE = S.BATCH_SCHEDULE_TYPE
  ,BATCH_SCHEDULE_LAST = S.BATCH_SCHEDULE_LAST
  ,PATTERN_COLUMNS = S.PATTERN_COLUMNS
  ,GROUPBY_COLUMNS = S.GROUPBY_COLUMNS
  ,GROUPBY_PATTERN = S.GROUPBY_PATTERN
  ,GROUPBY_FLEXIBLE = S.GROUPBY_FLEXIBLE
  ,AGGREGATE_COLUMNS = S.AGGREGATE_COLUMNS
  ,AGGREGATE_FUNCTIONS = S.AGGREGATE_FUNCTIONS
  ,DEFAULT_PROCEDURE = S.DEFAULT_PROCEDURE
WHEN NOT MATCHED THEN INSERT (
	TARGET_LABEL
	,TARGET_TABLE
	,BATCH_CONTROL_COLUMN
	,BATCH_CONTROL_SIZE
	,BATCH_CONTROL_NEXT
	,BATCH_PROCESSED
	,BATCH_PROCESSING
	,BATCH_MICROCHUNK_CURRENT
	,BATCH_SCHEDULE_TYPE
	,BATCH_SCHEDULE_LAST
	,PATTERN_COLUMNS
	,GROUPBY_COLUMNS
	,GROUPBY_PATTERN
	,GROUPBY_FLEXIBLE
	,AGGREGATE_COLUMNS
	,AGGREGATE_FUNCTIONS
	,DEFAULT_PROCEDURE
	)
VALUES (
  S.TARGET_LABEL
	,S.TARGET_TABLE
	,S.BATCH_CONTROL_COLUMN
	,S.BATCH_CONTROL_SIZE
	,S.BATCH_CONTROL_NEXT
	,S.BATCH_PROCESSED
	,S.BATCH_PROCESSING
	,S.BATCH_MICROCHUNK_CURRENT
	,S.BATCH_SCHEDULE_TYPE
	,S.BATCH_SCHEDULE_LAST
	,S.PATTERN_COLUMNS
	,S.GROUPBY_COLUMNS
	,S.GROUPBY_PATTERN
	,S.GROUPBY_FLEXIBLE
	,S.AGGREGATE_COLUMNS
	,S.AGGREGATE_FUNCTIONS
	,S.DEFAULT_PROCEDURE
);
--
-- Register the source data table
--
-- DELETE FROM DATA_ALLOCATION_BUCKETS WHERE TARGET_TABLE = '_TEST_DATA_TARGET_2' AND BUCKET_TABLE = '_TEST_DATA_TARGET_1';
-- Update or add the aggregation source
MERGE INTO DATA_ALLOCATION_BUCKETS D
USING (
  SELECT 'Test: dummy allocation target 2 basket 1' BUCKET_LABEL
    	,$1 TARGET_TABLE
    	,$2 BUCKET_TABLE
    	,false BUCKET_ENABLED
    	,15 PATTERN_DEFAULT
    	,false PATTERN_FLEXIBLE
    	,DATEADD(MINUTE, ROUND(DATEDIFF(MINUTE, '2000-01-01',TO_TIMESTAMP_NTZ(CURRENT_TIMESTAMP()))/5)*5,'2000-01-01') DATA_AVAILABLETIME
    	,NULL DATA_CHECKSCHEDULE
    	,$3 TRANSFORMATION
  FROM VALUES (
		'_TEST_DATA_TARGET_2'
		,'_TEST_DATA_TARGET_1'
		,$$
		SELECT DATA_PATTERN(PARSE_JSON('[1,0,1,0,1,1,1,1,0,0,0]')) DATA_PT
			--,\'_TEST_DATA_SOURCE_1\'::VARCHAR DATA_DN
			,DATE(DATA_DT) DATA_DT
			--,DATE_PART(HOUR, DATA_DT) DATA_HR
			,TO_TIMESTAMP_NTZ (DATA_DT) DATA_TS
			,DATA_I1
			,DATA_I2
			,DATA_I3
			--,DATA_A1
			--,DATA_A2
			--,DATA_A3
			,VSUM_I1
			,VCNT_I2
			,VSUM_D1
			,VAVG_D2
		FROM _TEST_DATA_TARGET_2
		$$
  )
) S
ON D.TARGET_TABLE = S.TARGET_TABLE AND D.BUCKET_TABLE = S.BUCKET_TABLE
WHEN MATCHED THEN UPDATE SET ID = D.ID
	,BUCKET_LABEL = S.BUCKET_LABEL
	--,TARGET_TABLE = S.TARGET_TABLE
	--,BUCKET_TABLE = S.BUCKET_TABLE
	,BUCKET_ENABLED = S.BUCKET_ENABLED
	,PATTERN_DEFAULT = S.PATTERN_DEFAULT
	,PATTERN_FLEXIBLE = S.PATTERN_FLEXIBLE
	,DATA_AVAILABLETIME = S.DATA_AVAILABLETIME
	,DATA_CHECKSCHEDULE = S.DATA_CHECKSCHEDULE
	,TRANSFORMATION = S.TRANSFORMATION
WHEN NOT MATCHED THEN INSERT (
	BUCKET_LABEL
	,TARGET_TABLE
	,BUCKET_TABLE
	,BUCKET_ENABLED
	,PATTERN_DEFAULT
	,PATTERN_FLEXIBLE
	,DATA_AVAILABLETIME
	,DATA_CHECKSCHEDULE
	,TRANSFORMATION
	)
VALUES (
	S.BUCKET_LABEL
	,S.TARGET_TABLE
	,S.BUCKET_TABLE
	,S.BUCKET_ENABLED
	,S.PATTERN_DEFAULT
	,S.PATTERN_FLEXIBLE
	,S.DATA_AVAILABLETIME
	,S.DATA_CHECKSCHEDULE
	,S.TRANSFORMATION
	)
;
--
-- Test new added source setting
--
-- CALL DATA_ALLOCATOR ('<target table>', <script only>, <log details>, <disabled only>, '<test date>');
CALL DATA_ALLOCATOR ('_TEST_DATA_TARGET_2', 1, 0, 1, TO_VARCHAR(CURRENT_DATE()-1));
--
-- Exclude new added source from testing
--
UPDATE DATA_ALLOCATION_BUCKETS
SET BUCKET_ENABLED = TRUE
WHERE TARGET_TABLE = '_TEST_DATA_TARGET_2'
AND BUCKET_TABLE IN ('_TEST_DATA_TARGET_1')
;
--
--
-- Process all
--
-- CALL DATA_ALLOCATOR ('<target table>', <script only>, <log details>);
CALL DATA_ALLOCATOR('_TEST_DATA_TARGET_2', 0, 1);
--
